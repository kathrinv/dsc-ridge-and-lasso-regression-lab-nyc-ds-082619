{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge and Lasso Regression - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll practice your knowledge of Ridge and Lasso regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use Lasso and ridge regression in Python\n",
    "* Compare Lasso and Ridge with standard regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Housing Prices Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at yet another house pricing data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('Housing_Prices/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "MSZoning         1460 non-null object\n",
      "LotFrontage      1201 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "Street           1460 non-null object\n",
      "Alley            91 non-null object\n",
      "LotShape         1460 non-null object\n",
      "LandContour      1460 non-null object\n",
      "Utilities        1460 non-null object\n",
      "LotConfig        1460 non-null object\n",
      "LandSlope        1460 non-null object\n",
      "Neighborhood     1460 non-null object\n",
      "Condition1       1460 non-null object\n",
      "Condition2       1460 non-null object\n",
      "BldgType         1460 non-null object\n",
      "HouseStyle       1460 non-null object\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "RoofStyle        1460 non-null object\n",
      "RoofMatl         1460 non-null object\n",
      "Exterior1st      1460 non-null object\n",
      "Exterior2nd      1460 non-null object\n",
      "MasVnrType       1452 non-null object\n",
      "MasVnrArea       1452 non-null float64\n",
      "ExterQual        1460 non-null object\n",
      "ExterCond        1460 non-null object\n",
      "Foundation       1460 non-null object\n",
      "BsmtQual         1423 non-null object\n",
      "BsmtCond         1423 non-null object\n",
      "BsmtExposure     1422 non-null object\n",
      "BsmtFinType1     1423 non-null object\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinType2     1422 non-null object\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "Heating          1460 non-null object\n",
      "HeatingQC        1460 non-null object\n",
      "CentralAir       1460 non-null object\n",
      "Electrical       1459 non-null object\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "KitchenQual      1460 non-null object\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Functional       1460 non-null object\n",
      "Fireplaces       1460 non-null int64\n",
      "FireplaceQu      770 non-null object\n",
      "GarageType       1379 non-null object\n",
      "GarageYrBlt      1379 non-null float64\n",
      "GarageFinish     1379 non-null object\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "GarageQual       1379 non-null object\n",
      "GarageCond       1379 non-null object\n",
      "PavedDrive       1460 non-null object\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "PoolQC           7 non-null object\n",
      "Fence            281 non-null object\n",
      "MiscFeature      54 non-null object\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "SaleType         1460 non-null object\n",
      "SaleCondition    1460 non-null object\n",
      "SalePrice        1460 non-null int64\n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make a selection of the data by removing some of the data with `dtype = object`, this way our first model only contains **continuous features**\n",
    "\n",
    "Make sure to remove the SalesPrice column from the predictors (which you store in `X`), then replace missing inputs by the median per feature.\n",
    "\n",
    "Store the target in `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create y\n",
    "y = df['SalePrice'].copy()\n",
    "\n",
    "# remove \"object\"-type features and SalesPrice from `X`\n",
    "X = df.copy()\n",
    "X.drop('SalePrice', axis = 1, inplace=True)\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == 'object':\n",
    "        X.drop(column, axis=1, inplace=True)\n",
    "\n",
    "# Impute null values\n",
    "for column in X.columns:\n",
    "    if X[column].isna().sum() != 0:\n",
    "#         print(column)\n",
    "#         print(X[column].value_counts())\n",
    "        median = X[column].median()\n",
    "        X[column].fillna(median, inplace=True)\n",
    "#         print(median)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the information of `X` again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 37 columns):\n",
      "Id               1460 non-null int64\n",
      "MSSubClass       1460 non-null int64\n",
      "LotFrontage      1460 non-null float64\n",
      "LotArea          1460 non-null int64\n",
      "OverallQual      1460 non-null int64\n",
      "OverallCond      1460 non-null int64\n",
      "YearBuilt        1460 non-null int64\n",
      "YearRemodAdd     1460 non-null int64\n",
      "MasVnrArea       1460 non-null float64\n",
      "BsmtFinSF1       1460 non-null int64\n",
      "BsmtFinSF2       1460 non-null int64\n",
      "BsmtUnfSF        1460 non-null int64\n",
      "TotalBsmtSF      1460 non-null int64\n",
      "1stFlrSF         1460 non-null int64\n",
      "2ndFlrSF         1460 non-null int64\n",
      "LowQualFinSF     1460 non-null int64\n",
      "GrLivArea        1460 non-null int64\n",
      "BsmtFullBath     1460 non-null int64\n",
      "BsmtHalfBath     1460 non-null int64\n",
      "FullBath         1460 non-null int64\n",
      "HalfBath         1460 non-null int64\n",
      "BedroomAbvGr     1460 non-null int64\n",
      "KitchenAbvGr     1460 non-null int64\n",
      "TotRmsAbvGrd     1460 non-null int64\n",
      "Fireplaces       1460 non-null int64\n",
      "GarageYrBlt      1460 non-null float64\n",
      "GarageCars       1460 non-null int64\n",
      "GarageArea       1460 non-null int64\n",
      "WoodDeckSF       1460 non-null int64\n",
      "OpenPorchSF      1460 non-null int64\n",
      "EnclosedPorch    1460 non-null int64\n",
      "3SsnPorch        1460 non-null int64\n",
      "ScreenPorch      1460 non-null int64\n",
      "PoolArea         1460 non-null int64\n",
      "MiscVal          1460 non-null int64\n",
      "MoSold           1460 non-null int64\n",
      "YrSold           1460 non-null int64\n",
      "dtypes: float64(3), int64(34)\n",
      "memory usage: 422.1 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use this data to perform a first naive linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the R squared and the MSE for both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set: 1300136785.77\n",
      "R-squared for training set: 0.8\n",
      "MSE for test set: 864883615.27\n",
      "R-squared for test set: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, r2_score\n",
    "\n",
    "# Split in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=144)\n",
    "# Fit the model and print R2 and MSE for train and test\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "MSE = mean_squared_error(y_train, linreg.predict(X_train))\n",
    "R2 = r2_score(y_train, linreg.predict(X_train))\n",
    "\n",
    "# linreg.fit(X_test, y_test)\n",
    "MSE_test = mean_squared_error(y_test, linreg.predict(X_test))\n",
    "R2_test = r2_score(y_test, linreg.predict(X_test))\n",
    "print(f\"MSE for training set: {round(MSE,2)}\")\n",
    "print(f\"R-squared for training set: {round(R2,2)}\")\n",
    "print(f\"MSE for test set: {round(MSE_test,2)}\")\n",
    "print(f\"R-squared for test set: {round(R2_test,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't normalized our data, let's create a new model that uses `preprocessing.scale` to scale our predictors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Scale the data and perform train test split\n",
    "scale = MinMaxScaler()\n",
    "transformed_X = scale.fit_transform(X)\n",
    "\n",
    "X_train_trans, X_test_trans, y_train, y_test = train_test_split(transformed_X, y, random_state=144)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set: 860911178.85\n",
      "R-squared for training set: 0.8\n",
      "MSE for test set: 864883615.27\n",
      "R-squared for test set: 0.85\n"
     ]
    }
   ],
   "source": [
    "linreg_trans = LinearRegression()\n",
    "linreg_trans.fit(X_train_trans, y_train)\n",
    "MSE = mean_squared_error(y_train, linreg_trans.predict(X_train_trans))\n",
    "r2 = r2_score(y_train, linreg_trans.predict(X_train_trans))\n",
    "\n",
    "MSE = mean_squared_error(y_test, linreg_trans.predict(X_test_trans))\n",
    "r2 = r2_score(y_test, linreg_trans.predict(X_test_trans))\n",
    "print(f\"MSE for training set: {round(MSE,2)}\")\n",
    "print(f\"R-squared for training set: {round(R2,2)}\")\n",
    "print(f\"MSE for test set: {round(MSE_test,2)}\")\n",
    "print(f\"R-squared for test set: {round(R2_test,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model hasn't included dummy variables so far: let's use the \"object\" variables again and create dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = df.copy()\n",
    "X_cat.drop('SalePrice', axis = 1, inplace=True)\n",
    "for column in X_cat.columns:\n",
    "    if X_cat[column].dtype != 'object':\n",
    "        X_cat.drop(column, axis=1, inplace=True)\n",
    "# X_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dummies\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# X_cat = OneHotEncoder(X_cat)\n",
    "X_cat = pd.get_dummies(X_cat, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge `x_cat` together with our scaled `X` so you have one big predictor dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.concat([pd.DataFrame(transformed_X), X_cat], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the same linear regression on this data and print out R-squared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set: 429657488.77\n",
      "R-squared for training set: 0.93\n",
      "MSE for test set: 4.098809727345456e+28\n",
      "R-squared for test set: -6.930829492395863e+18\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y, random_state=144)\n",
    "# Fit the model and print R2 and MSE for train and test\n",
    "linreg_all = LinearRegression()\n",
    "linreg_all.fit(X_train, y_train)\n",
    "MSE = mean_squared_error(y_train, linreg_all.predict(X_train))\n",
    "R2 = r2_score(y_train, linreg_all.predict(X_train))\n",
    "\n",
    "# linreg.fit(X_test, y_test)\n",
    "MSE_test = mean_squared_error(y_test, linreg_all.predict(X_test))\n",
    "R2_test = r2_score(y_test, linreg_all.predict(X_test))\n",
    "print(f\"MSE for training set: {round(MSE,2)}\")\n",
    "print(f\"R-squared for training set: {round(R2,2)}\")\n",
    "print(f\"MSE for test set: {round(MSE_test,2)}\")\n",
    "print(f\"R-squared for test set: {round(R2_test,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the severe overfitting above; our training R squared is quite high, but the testing R squared is negative! Our predictions are far off. Similarly, the scale of the Testing MSE is orders of magnitude higher than that of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Ridge and Lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use all the data (normalized features and dummy categorical variables) and perform Lasso and Ridge regression for both! Each time, look at R-squared and MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set: 430136898.94\n",
      "R-squared for training set: 0.93\n",
      "MSE for test set: 2956638643.03\n",
      "R-squared for test set: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "lasso = Lasso(alpha=1.0)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "MSE = mean_squared_error(y_train, lasso.predict(X_train))\n",
    "R2 = r2_score(y_train, lasso.predict(X_train))\n",
    "\n",
    "# linreg.fit(X_test, y_test)\n",
    "MSE_test = mean_squared_error(y_test, lasso.predict(X_test))\n",
    "R2_test = r2_score(y_test, lasso.predict(X_test))\n",
    "# print(lasso.coef_)\n",
    "print(f\"MSE for training set: {round(MSE,2)}\")\n",
    "print(f\"R-squared for training set: {round(R2,2)}\")\n",
    "print(f\"MSE for test set: {round(MSE_test,2)}\")\n",
    "print(f\"R-squared for test set: {round(R2_test,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a higher regularization parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set: 451526183.73\n",
      "R-squared for training set: 0.93\n",
      "MSE for test set: 1592927031.77\n",
      "R-squared for test set: 0.73\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=10.0)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "MSE = mean_squared_error(y_train, lasso.predict(X_train))\n",
    "R2 = r2_score(y_train, lasso.predict(X_train))\n",
    "\n",
    "# linreg.fit(X_test, y_test)\n",
    "MSE_test = mean_squared_error(y_test, lasso.predict(X_test))\n",
    "R2_test = r2_score(y_test, lasso.predict(X_test))\n",
    "# print(lasso.coef_)\n",
    "print(f\"MSE for training set: {round(MSE,2)}\")\n",
    "print(f\"R-squared for training set: {round(R2,2)}\")\n",
    "print(f\"MSE for test set: {round(MSE_test,2)}\")\n",
    "print(f\"R-squared for test set: {round(R2_test,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set: 568187322.99\n",
      "R-squared for training set: 0.91\n",
      "MSE for test set: 731842756.36\n",
      "R-squared for test set: 0.88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "MSE = mean_squared_error(y_train, ridge.predict(X_train))\n",
    "R2 = r2_score(y_train, ridge.predict(X_train))\n",
    "\n",
    "# linreg.fit(X_test, y_test)\n",
    "MSE_test = mean_squared_error(y_test, ridge.predict(X_test))\n",
    "R2_test = r2_score(y_test, ridge.predict(X_test))\n",
    "# print(lasso.coef_)\n",
    "print(f\"MSE for training set: {round(MSE,2)}\")\n",
    "print(f\"R-squared for training set: {round(R2,2)}\")\n",
    "print(f\"MSE for test set: {round(MSE_test,2)}\")\n",
    "print(f\"R-squared for test set: {round(R2_test,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With default parameter (alpha = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for training set: 763232510.22\n",
      "R-squared for training set: 0.88\n",
      "MSE for test set: 721227528.36\n",
      "R-squared for test set: 0.88\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=10.0)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "MSE = mean_squared_error(y_train, ridge.predict(X_train))\n",
    "R2 = r2_score(y_train, ridge.predict(X_train))\n",
    "\n",
    "# linreg.fit(X_test, y_test)\n",
    "MSE_test = mean_squared_error(y_test, ridge.predict(X_test))\n",
    "R2_test = r2_score(y_test, ridge.predict(X_test))\n",
    "# print(lasso.coef_)\n",
    "print(f\"MSE for training set: {round(MSE,2)}\")\n",
    "print(f\"R-squared for training set: {round(R2,2)}\")\n",
    "print(f\"MSE for test set: {round(MSE_test,2)}\")\n",
    "print(f\"R-squared for test set: {round(R2_test,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the metrics, what are your main conclusions?   \n",
    "\n",
    "Conclusions here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare number of parameter estimates that are (very close to) 0 for Ridge and Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare with the total length of the parameter space and draw conclusions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of coefficients that became zero under Ridge Regression: 5\n",
      "Proportion of coefficients that became zero under Ridge Regression: 0.02032520325203252\n"
     ]
    }
   ],
   "source": [
    "# number of Ridge params almost zero\n",
    "n = len(ridge.coef_)\n",
    "num_zero = [x for x in ridge.coef_ if x < 0.0001 if x > -0.0001]\n",
    "print(f\"Number of coefficients that became zero under Ridge Regression: {len(num_zero)}\")\n",
    "print(f\"Proportion of coefficients that became zero under Ridge Regression: {len(num_zero)/n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of coefficients that became zero under Lasso Regression: 49\n",
      "Proportion of coefficients that became zero under Lasso Regression: 0.1991869918699187\n"
     ]
    }
   ],
   "source": [
    "# number of Lasso params almost zero\n",
    "n = len(lasso.coef_)\n",
    "num_zero = [x for x in lasso.coef_ if x < 0.0001 if x > -0.0001]\n",
    "print(f\"Number of coefficients that became zero under Lasso Regression: {len(num_zero)}\")\n",
    "print(f\"Proportion of coefficients that became zero under Lasso Regression: {len(num_zero)/n}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso was very effective to essentially perform variable selection and remove about 25% of the variables from your model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! You now know how to perform Lasso and Ridge regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
